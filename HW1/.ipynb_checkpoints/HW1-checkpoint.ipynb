{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0db959ba",
   "metadata": {},
   "source": [
    "# Homework 1\n",
    "## Due Sept. 8, 2021 by 11:59pm via BlackBoard\n",
    "\n",
    "This homework involves input from a file, a little regular expressions, string processing and word counting. (40 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8208aa",
   "metadata": {},
   "source": [
    "### David Proksch - proks1dl\n",
    "### Fall 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a37404",
   "metadata": {},
   "source": [
    "In this homework, you are given the task of reading a text file (attached with the assignment) and counting the number of occurrences of each unique word (case insensitive) exist, writing the result (sorted lexicographically) to an output text file named \"Counts.txt\". Submit both the .ipynb (or .py) file used to do the word count, plus your output text file. Beware of non-alphabetic characters like periods, commas and apostrophes!\n",
    "\n",
    "Sample input:\n",
    "\n",
    "    The dog ate the cat's food, then went to sleep. \n",
    "    \n",
    "    The end.\n",
    "    \n",
    "Sample output:\n",
    "\n",
    "    ate 1\n",
    "    cat 1\n",
    "    dog 1\n",
    "    end 1\n",
    "    food 1\n",
    "    sleep 1\n",
    "    the 3\n",
    "    then 1\n",
    "    to 1\n",
    "    went 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5b45be",
   "metadata": {},
   "source": [
    "# Input the file into a list of strings, then tokenize each element of the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3baa71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk contractions > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "341a9fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/dproksch/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "import string\n",
    "\n",
    "from nltk import word_tokenize\n",
    "import contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70f098ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = './Sample1.txt'\n",
    "path = './homeworkinput1.txt'\n",
    "\n",
    "inputFile = open(path,'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca624e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = inputFile.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee27c3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(lines):\n",
    "    punct = list(string.punctuation)\n",
    "    punct.append('\\'s') # Add possessive to the black list\n",
    "    punct.append('’')\n",
    "    #print(punct)\n",
    "    words = []\n",
    "    for line in lines:\n",
    "        \n",
    "        #print(word_tokenize(line))\n",
    "        for word in word_tokenize(line):\n",
    "            if word not in punct:\n",
    "                if '’s' in word:\n",
    "                    print(word)\n",
    "                if 's' != word:\n",
    "                    words.append(contractions.fix(word.lower()).strip())\n",
    "\n",
    "    return words\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e096ac9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function TextIOWrapper.close()>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "outputPath = \"./Counts.txt\"\n",
    "\n",
    "outputFile = open(outputPath,'w')\n",
    "\n",
    "with outputFile as of:\n",
    "    for w,c in Counter(parse(lines)).most_common():\n",
    "        of.write(\"{0}|{1}\\n\".format(w,c))\n",
    "\n",
    "outputFile.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca58b040",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
